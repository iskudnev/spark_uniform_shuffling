# spark_uniform_shuffling
### Discovering approach for uniform shuffling implementation in spark job  


### Разработка подхода к реализации равномерного шафлинга в spark-джобе  
**Предпосылка к разработке метода** — обеспечение равномерного разбиения набора данных при использовании агрегационных пользовательских pandas-функций в spark, сохраняя преимущество применения векторных вычислений. Применение таких функций нужно:
 - при инференсе ML/LLM-моделей, когда требуется возврат из функции нескольких столбцов значений;
 - при фильтрации, соединении и прочих действиях, приводящих к изменению числа строк исходной группы.

При выборе поля группировки для последующего применения pandas-функции возникают проблемы:
 - группировка данных на идентификатор пользователя/клиента приведет к схлопыванию группы в единицы строк, что сведет на нет потенциал векторных вычислений и снизит скорость обработки;
 - генерация целочисленной последовательности в качестве ключа группировки в виду малой мощности такого множества приведет перекосу вычислительной нагрузки на исполнителей заданий в 20% заданий, что иногда чревато падением всего процесса обработки.

**Идея метода** заключается в возможности сгенерировать выборку заданного размера из ключей, которые при шаффлинге будут гарантированно оказываться в разных партициях, исключая их перекосы по объему данных и тем самым повышая производительность и робастность обработки данных  
Шаффлинг (перемешивание) данных в ходе spark-джобы происходит при выполнении широких трансформаций над набором данных, находящихся, например в распределенной файловой системе hadoop. Под широкими трансформациями в spark понимают группировку набора данных для проведения агрегации или соединение нескольких наборов данных. В распределенной файловой системе файлы, относящиеся к одному набору данных, могут физически находиться на разных узлах кластера hadoop, поэтому шаффлинг при проведении широких трансформаций необходим, чтобы, например, при группировке строки данных с идентичными значениями ключей из разных узлов кластера hadoop были перемещены на конкретный узел и далее сагрегированы в рамках одной партиции (т.е. некоторой части исходного набора данных, полученной в ходе его разбиения/шаффлинга). Для определения, в какой партиции строка будет обработана, в spark используется алгоритм:
 - вычисление хэш-функции по ключу группировки `hash`;
 - вычисление остатка от деления `hash` на заданное число групп разделения набора данных.

Значение остатка `mod` и определяет номер партиции для строки.

**Реализация метода** 
 - Определение числа групп, на которые будут разбиты данные. Это может быть или заданное на уровне конфигурации spark число шаффл-партиций, или заданное число, определенное из объема исходных данных, или число групп, исходящее из бизнес-смысла поля разбиения (например, разбиение по филиалам предприятия);
 - Генерация длинной последовательности целых чисел заданного типа от 0 до 1 млн.;
 - Вычисление хэш-функции и остатка на значениях длинной последовательности по алгоритму, описанному выше;
 - Отбор по одному значению из длинной последовательности, приходящемуся на соответствующий остаток.

Подробности реализации в ноутбуке `spark_example.ipynb`  
Выражаю благодарность за деятельный вклад @DenisRubakin